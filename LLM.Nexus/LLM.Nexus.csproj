<Project Sdk="Microsoft.NET.Sdk">

    <PropertyGroup>
        <TargetFramework>netstandard2.0</TargetFramework>
        <LangVersion>latest</LangVersion>
        <Nullable>enable</Nullable>

        <PackageId>LLM.Nexus</PackageId>
        <Version>2.1.1</Version>
        <Authors>Alexandros Mouratidis</Authors>
        <Company>Alexandros Mouratidis</Company>

        <Description>A unified abstraction layer for multiple LLM providers (OpenAI, Anthropic, Google) with support for multiple simultaneous providers, named configurations, dependency injection, rich response metadata, and extensible architecture.</Description>
        <PackageTags>LLM;AI;OpenAI;Anthropic;Google;Gemini;Claude;GPT;ChatGPT;NLP;Machine-Learning;Multi-Provider</PackageTags>

        <PackageProjectUrl>https://github.com/Mouratid/llm.nexus</PackageProjectUrl>
        <RepositoryUrl>https://github.com/Mouratid/llm.nexus</RepositoryUrl>
        <RepositoryType>git</RepositoryType>
        <PackageLicenseExpression>MIT</PackageLicenseExpression>

        <PackageReadmeFile>README.md</PackageReadmeFile>
        <GenerateDocumentationFile>true</GenerateDocumentationFile>
        <NoWarn>$(NoWarn);CS1591</NoWarn>

        <IncludeSymbols>true</IncludeSymbols>
        <SymbolPackageFormat>snupkg</SymbolPackageFormat>
        <PublishRepositoryUrl>true</PublishRepositoryUrl>
        <EmbedUntrackedSources>true</EmbedUntrackedSources>

        <PackageReleaseNotes>v2.1.1 - Multimodal Support
• NEW: Multimodal support - Send images, documents, and files to all providers
• NEW: FileContent class with FromFile, FromBytes, and FromUrl helper methods
• NEW: MediaType enum for Image, Document, Audio, and Video content
• NEW: Files property on LLMRequest for vision and document analysis
• Google provider now supports multimodal requests with images and documents
• OpenAI and Anthropic providers support multimodal requests (images, documents)
• 82 tests passing (added 17 file handling tests)
• All existing functionality maintained

Example: var request = new LLMRequest { Prompt = "What's in this image?", Files = new List&lt;FileContent&gt; { FileContent.FromFile("photo.jpg", MediaType.Image) } };</PackageReleaseNotes>

        <PackageIcon>Icon.png</PackageIcon>
    </PropertyGroup>

    <ItemGroup>
        <PackageReference Include="Google_GenerativeAI" />
        <PackageReference Include="Microsoft.Extensions.Options" />
        <PackageReference Include="Microsoft.Extensions.Options.ConfigurationExtensions" />
        <PackageReference Include="Microsoft.Extensions.Options.DataAnnotations" />
        <PackageReference Include="OpenAI" />
        <PackageReference Include="Anthropic.SDK" />
    </ItemGroup>

    <ItemGroup>
        <None Include="..\README.md" Pack="true" PackagePath="\" />
        <None Include="Icon.png" Pack="true" PackagePath="\" />
    </ItemGroup>

    <ItemGroup>
      <Folder Include="Providers\" />
    </ItemGroup>

    <ItemGroup>
      <AssemblyAttribute Include="System.Runtime.CompilerServices.InternalsVisibleToAttribute">
        <_Parameter1>LLM.Nexus.Tests</_Parameter1>
      </AssemblyAttribute>
      <AssemblyAttribute Include="System.Runtime.CompilerServices.InternalsVisibleToAttribute">
        <_Parameter1>DynamicProxyGenAssembly2</_Parameter1>
      </AssemblyAttribute>
    </ItemGroup>

</Project>
